{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23764a7-0946-4156-bf6c-4683128ed364",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c32be42-0753-4741-a676-917ebcf1bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd532e-c716-45cf-adf2-349dd78e8dcc",
   "metadata": {},
   "source": [
    "## Processing Data Input (Guitar Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd4f09b0-d66b-4d05-852c-05e6a28be44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeKey(t):\n",
    "    return t[0]\n",
    "\n",
    "def loadNoteData(f):\n",
    "    #f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "   # data = f.read()\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    #pprint.pprint(notes)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aeaa92e3-b752-4116-afc1-ecac01404cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "        source_audio = source_audio.astype(np.float32) / max(max(source_audio),abs(min(source_audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca4afee-256c-4ff9-b55f-ea68b30e9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to process the raw audio data.\n",
    "def x_data_process(raw_data):\n",
    "    scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "    scaled = scaler.fit_transform(raw_data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8917c650-eb1d-41ac-b273-5fd799a8eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change this so it pads to match the shape of frame. not just the length\n",
    "def pad(proper_size, frame):\n",
    "    padsize = winSize-len(frame)\n",
    "    temp = None\n",
    "    if len(frame.shape) > 1:\n",
    "        temp = np.zeros((frame.shape[0],padsize))\n",
    "    else:\n",
    "        temp = np.zeros(padsize)\n",
    "\n",
    "    return np.concatenate((frame,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbcb0d9e-2413-4e5f-8695-7a41674c341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  testCount = 0\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    testCount += 1\n",
    "\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = audio[o:o+winSize]\n",
    "\n",
    "    if original_frame_size == 0:\n",
    "      original_frame_size = frame.shape\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels,testCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0fc0a8c-a91f-4131-bde1-aa7c11c39e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsneFit(X, comps):\n",
    "    tsne = TSNE(comps, learning_rate='auto', init='pca')\n",
    "    result = tsne.fit_transform(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624214b-1486-4939-ad1d-a3a0edb4f584",
   "metadata": {},
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0dbd30e-0ddf-440f-b43f-1c8cd354da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Taking the song path, trained model, and same hopSize and winSize as used in training,\n",
    "Converts song into predicted midi information\"\"\"\n",
    "def predict(song_path, model, hopSize, winSize):\n",
    "    \n",
    "    audio,sr = load_audio_file(song_path, scale=False)\n",
    "    offsets = np.arange(0,len(audio),hopSize)\n",
    "    x_data = []\n",
    "    for (i,o) in enumerate(offsets):\n",
    "        frame = audio[o:o+winSize]\n",
    "        #pad\n",
    "        if len(frame) < winSize:\n",
    "            frame = pad(winSize, frame)\n",
    "\n",
    "        #append to features\n",
    "        x_data.append(frame)\n",
    "\n",
    "    #preprocess data\n",
    "    x_data = x_data_process(x_data)\n",
    "\n",
    "    #column 0 is note, column 1 is time\n",
    "    midi_info = np.zeros((len(offsets),2))\n",
    "    raw_results = model.predict(x_data)\n",
    "\n",
    "    for i,frame_note in enumerate(raw_results):\n",
    "        midi_info[i][0] = frame_note\n",
    "        midi_info[i][1] = hopSize*i/sr\n",
    "\n",
    "        #TODO: create proper midi file from this note / time information\n",
    "          #Also determine method to covert midi into sheet music\n",
    "\n",
    "    return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11f6e2-4fff-4187-979b-11888e69f2b0",
   "metadata": {},
   "source": [
    "## Driver to load data and # of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e819390-a93f-4ea5-8359-fc0f5495aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a48055c-1f47-4bfb-ad5d-9f108088a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 5\n",
    "counter = numSongs\n",
    "\n",
    "notecounter = 0\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "XData_pre,YData_pre = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "    song = os.path.join(song_path,song_file)\n",
    "    jam = os.path.join(jam_path,jam_file)\n",
    "    \n",
    "    audio,sr = load_audio_file(song, scale=False)\n",
    "    note_info = loadNoteData(jam)\n",
    "\n",
    "    # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "    XData,YData,notecount = songProcess(audio,note_info,sr, hopSize, winSize)\n",
    "\n",
    "    #Prescaled Xdata for experiement\n",
    "    audio_prescaled,sr = load_audio_file(song,scale=True)\n",
    "    XData_pre,YData_pre,notecount = songProcess(audio_prescaled,note_info,sr,hopSize,winSize)\n",
    "\n",
    "    notecounter += notecount\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1127834-4368-4e8b-8047-985f7c98d6db",
   "metadata": {},
   "source": [
    "## Neural Network Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5024459-86dc-4d95-bdc6-8d1d0ebc8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(XTrain, XTest, YTrain, YTest, hidden_size, max_iter, solver, activation):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=hidden_size, max_iter=max_iter, alpha=0.0001, \n",
    "                         learning_rate_init=0.001, solver=solver, activation=activation)\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de4822a9-b315-4b3c-a4e8-f21a730965f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.49308380797396256\n",
      "CPU times: user 3min 22s, sys: 25.9 s, total: 3min 48s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN Using No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "hidden_size=(60,500)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "NN_1_accuracy, NN_1 = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",NN_1_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f47c1b20-f4cd-4536-9eab-31c6cae9d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.7192839707078926\n",
      "CPU times: user 10min 49s, sys: 1min 12s, total: 12min 2s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN Using Post Scaling\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "hidden_size=(60,500)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "NN_2_accuracy, NN_2 = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",NN_2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b76e03a-bb23-4d9f-a759-b7fdae044ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.8096013018714402\n",
      "CPU times: user 16min 32s, sys: 1min 41s, total: 18min 13s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN Using Pre Scaling\n",
    "XData_pre = np.array(XData_pre)\n",
    "XData_pre = XData_pre / max(XData_pre.max(), abs(XData_pre.min()))\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_pre,YData_pre,test_size=0.2)\n",
    "hidden_size=(60,500)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "NN_3_accuracy, NN_3 = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",NN_3_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29d59dbd-4ec4-4c57-a832-a0353c12154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.2957689178193653\n",
      "CPU times: user 7min 2s, sys: 26.5 s, total: 7min 29s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN Using TSNE Scaling\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "hidden_size=(60,500)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "NN_4_accuracy, NN_4 = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",NN_4_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36e76d-413a-4954-af5e-7b59a4769c6b",
   "metadata": {},
   "source": [
    "### NN Results \n",
    "\n",
    "After the above test cases we found the Pre Scaling method for the data to perform the best for the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c9a90-f462-474f-bfb2-75af91c9457b",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a517570-b956-41c3-bec1-c39d7c2b9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'rbf', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5c8ec2c-6150-4d35-a9a0-096b6cf78e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polySVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'poly', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956de12-dc81-4639-8971-fa731a4dc4d8",
   "metadata": {},
   "source": [
    "### RBF Kernel - Gaussian SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77a888bc-530b-4df1-8bc9-64ef7537b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM Model Test Accuracy: 0.8429617575264443\n",
      "CPU times: user 2min 12s, sys: 469 ms, total: 2min 13s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RBF Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "GSVM_1_accuracy, GSVM_1 = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",GSVM_1_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4aa6f7dc-c6eb-4de2-82a1-bce42296faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM Model Test Accuracy: 0.42799023596419855\n",
      "CPU times: user 1min 30s, sys: 267 ms, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RBF Kernel - Post Scaling\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "GSVM_2_accuracy, GSVM_2 = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",GSVM_2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8c61d36-3792-4792-9cd0-c2f25e6c1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM Model Test Accuracy: 0.43816110659072416\n",
      "CPU times: user 1min 36s, sys: 344 ms, total: 1min 36s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RBF Kernel - Pre Scaling\n",
    "XData_pre = np.array(XData_pre)\n",
    "XData_pre = XData_pre / max(XData_pre.max(), abs(XData_pre.min()))\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "GSVM_3_accuracy, GSVM3 = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",GSVM_3_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fca54906-bdd7-4f05-8869-9ae98b695f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM Model Test Accuracy: 0.5935720097640358\n",
      "CPU times: user 4min 58s, sys: 5.58 s, total: 5min 4s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RBF Kernel - TSNE Scaling\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "GSVM_4_accuracy, GSVM_4 = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",GSVM_4_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d53e0f-2383-40d5-8b84-60f81003430f",
   "metadata": {},
   "source": [
    "### Poly Kernel - Polynomial SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "137ddf7d-f17f-4600-b43c-4494b9f69a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly SVM Model Test Accuracy: 0.48942229454841335\n",
      "CPU times: user 2min 21s, sys: 316 ms, total: 2min 21s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Poly Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "PSVM_1_accuracy, PSVM_1 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_1_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e198aad-f6b3-442a-8820-c4c401f366f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly SVM Model Test Accuracy: 0.3698128559804719\n",
      "CPU times: user 1min 19s, sys: 251 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Poly Kernel - Post Scaling\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "PSVM_2_accuracy, PSVM_2 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f277cd41-5bba-4fa6-a92d-af971a66e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly SVM Model Test Accuracy: 0.36126932465419037\n",
      "CPU times: user 1min 25s, sys: 249 ms, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Poly Kernel - Pre Scaling\n",
    "XData_pre = np.array(XData_pre)\n",
    "XData_pre = XData_pre / max(XData_pre.max(), abs(XData_pre.min()))\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "PSVM_3_accuracy, PSVM_3 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_3_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311128c3-a2c3-4906-b427-65d93ec4a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Poly Kernel - TSNE Scaling\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "PSVM_4_accuracy, PSVM_4 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_4_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3ec99-5a0a-49b1-ace1-c59e5d81534e",
   "metadata": {},
   "source": [
    "### SVM Model Results\n",
    "\n",
    "Having run the different scaling methods on both a Gaussian SVM and Polynomial SVM we found the best model was the Gaussian. The best scaling method was also no scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce710d9-42d7-4228-93c7-878a621706ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
