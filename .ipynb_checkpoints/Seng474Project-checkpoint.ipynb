{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert to a '.py' file\n",
    "#!jupyter nbconvert --to script *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jams in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (1.3.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (2.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (1.16.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (5.1.1)\n",
      "Requirement already satisfied: mir_eval>=0.5 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jams) (0.7)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jsonschema>=3.0.0->jams) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jsonschema>=3.0.0->jams) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jsonschema>=3.0.0->jams) (21.4.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mir_eval>=0.5->jams) (1.7.3)\n",
      "Requirement already satisfied: future in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mir_eval>=0.5->jams) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->jams) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->jams) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.0->jams) (3.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: audiolazy in c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pwshn6LfKd5X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQE8nV4nh1f2"
   },
   "source": [
    "## Process input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zn8-Wa-XEcV9"
   },
   "outputs": [],
   "source": [
    "def timeKey(t):\n",
    "    return t[0]\n",
    "\n",
    "def loadNoteData(f):\n",
    "    #f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "   # data = f.read()\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    #pprint.pprint(notes)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "      source_audio = audio.astype(np.float32) / max(max(audio),abs(min(audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function to process the raw audio data.\n",
    "#local uses sklearn's MinMaxScaler\n",
    "#global divides all numbers in data by the largest absolute value in dataset\n",
    "def x_data_process(raw_data, method='local'):\n",
    "  scaled = raw_data\n",
    "  if method == 'local':\n",
    "    scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "    scaled = scaler.fit_transform(raw_data)\n",
    "  elif method == 'global':\n",
    "    scaled = np.array(raw_data)\n",
    "    scaled = scaled / max(scaled.max(), abs(scaled.min()))\n",
    "  return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Change this so it pads to match the shape of frame. not just the length\n",
    "def pad(proper_size, frame):\n",
    "  padsize = winSize-len(frame)\n",
    "  temp = None\n",
    "  if len(frame.shape) > 1:\n",
    "    temp = np.zeros((frame.shape[0],padsize))\n",
    "  else:\n",
    "    temp = np.zeros(padsize)\n",
    "\n",
    "  return np.concatenate((frame,temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iBBc63iIocsB"
   },
   "outputs": [],
   "source": [
    "#iterate through each song, one frame at a time based off hop and window size\n",
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  testCount = 0\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    testCount += 1\n",
    "\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = song_audio[o:o+winSize]\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels,testCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsneFit(X, comps):\n",
    "    tsne = TSNE(comps, learning_rate='auto', init='pca')\n",
    "    result = tsne.fit_transform(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Taking the song path, trained model, and same hopSize and winSize as used in training,\n",
    "Converts song into predicted midi information\"\"\"\n",
    "def predict(song_path, model, hopSize, winSize):\n",
    "\n",
    "  song_audio,sr = load_audio_file(song_path, scale=False)\n",
    "  offsets = np.arange(0,len(audio),hopSize)\n",
    "  x_data = []\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    frame = song_audio[o:o+winSize]\n",
    "    #pad\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to features\n",
    "    x_data.append(frame)\n",
    "\n",
    "  #preprocess data\n",
    "  x_data = x_data_process(x_data)\n",
    "\n",
    "  #column 0 is note, column 1 is time\n",
    "  midi_info = np.zeros((len(offsets),2))\n",
    "  raw_results = model.predict(x_data)\n",
    "\n",
    "  for i,frame_note in enumerate(raw_results):\n",
    "    midi_info[i][0] = frame_note\n",
    "    midi_info[i][1] = hopSize*i/sr\n",
    "\n",
    "    #TODO: create proper midi file from this note / time information\n",
    "      #Also determine method to covert midi into sheet music\n",
    "\n",
    "  return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data classification using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def neuralNetwork(XTrain, XTest, YTrain, YTest):\n",
    "  #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "  MLPC = MLPClassifier(hidden_layer_sizes=(71, 21), max_iter=10000, alpha=0.0001, learning_rate_init=0.001, solver='lbfgs')\n",
    "  MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "  return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "  #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "  svc = SVC(kernel = 'rbf', gamma = 0.1, C = 10)\n",
    "  svc.fit(XTrain, YTrain)\n",
    "\n",
    "  return accuracy_score(YTest, svc.predict(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linearSVM(XTrain, XTest, YTrain, YTest):\n",
    "  #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "  svc = LinearSVC(C = 0.0225)\n",
    "\n",
    "  svc.fit(XTrain, YTrain)\n",
    "  accuracy_score(YTest, svc.predict(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8DfjYyNg0NZ"
   },
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CkZh6bSmKhw3"
   },
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 5\n",
    "counter = numSongs\n",
    "\n",
    "notecounter = 0\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "  song = os.path.join(song_path,song_file)\n",
    "  jam = os.path.join(jam_path,jam_file)\n",
    "\n",
    "  audio,sr = load_audio_file(song, scale=False)\n",
    "  audio_prescaled,sr = load_audio_file(song,scale=True)\n",
    "  \n",
    "  note_info = loadNoteData(jam)\n",
    "\n",
    "# Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "  XData,YData,notecount = songProcess(audio,note_info,sr, hopSize=hopSize, winSize = winSize)\n",
    "\n",
    "\n",
    "  notecounter += notecount\n",
    "  counter -= 1\n",
    "  if counter == 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 accuracy: 0.596153846153846\n",
      "Method 2 accuracy: 0.5909340659340658\n"
     ]
    }
   ],
   "source": [
    "### XDATA SCALING EXPERIMENT\n",
    "#Method 1: perform a -1,1 scale on the audio file at initial loading. This scales audio files individually, not recognizing the values of other files\n",
    "#Method 2: perform a -1,1 scale at train test split via sklearn. This scaled audio files together, after they are loaded and concatenated.\n",
    "#Method 3: control. No scaling\n",
    "\n",
    "XData_global = x_data_process(XData,method='global')\n",
    "XData_local = x_data_process(XData)\n",
    "\n",
    "N_avg = 10\n",
    "results = {}\n",
    "for j,xdata in enumerate((XData_global,XData_local)):\n",
    "  results[j] = 0\n",
    "  XTrain,XTest,YTrain,YTest = train_test_split(xdata,YData,test_size=0.2)\n",
    "  for i in range(N_avg):\n",
    "    results[j] += neuralNetwork(XTrain,XTest,YTrain,YTest)[0]\n",
    "  results[j] /= N_avg\n",
    "\n",
    "print(\"Method 1 accuracy:\",results[0])\n",
    "print(\"Method 2 accuracy:\",results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5456, 1024)\n",
      "(5456, 2)\n",
      "0.5769230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arnal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "### XDATA USING TSNE\n",
    "XData_global = x_data_process(XData,method='global')\n",
    "XData_local = x_data_process(XData)\n",
    "\n",
    "XDataTsne = tsneFit(XData_local, 2)\n",
    "\n",
    "print(XData_local.shape)\n",
    "print(XDataTsne.shape)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTsne,YData,test_size=0.2)\n",
    "res = neuralNetwork(XTrain,XTest,YTrain,YTest)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.673992673992674\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = neuralNetwork(XTrain,XTest,YTrain,YTest)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.00000000e+01 0.00000000e+00]\n",
      " [4.90000000e+01 2.32199546e-02]\n",
      " [4.60000000e+01 4.64399093e-02]\n",
      " [4.90000000e+01 6.96598639e-02]\n",
      " [5.00000000e+01 9.28798186e-02]\n",
      " [4.60000000e+01 1.16099773e-01]\n",
      " [4.90000000e+01 1.39319728e-01]\n",
      " [4.20000000e+01 1.62539683e-01]\n",
      " [4.20000000e+01 1.85759637e-01]\n",
      " [4.90000000e+01 2.08979592e-01]]\n"
     ]
    }
   ],
   "source": [
    "## Call predict function\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "midi_info = predict(song,trained_model,hopSize,winSize)\n",
    "\n",
    "print(midi_info[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNV465-nwiWH"
   },
   "source": [
    "## Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YZJnOBjgghz7"
   },
   "outputs": [],
   "source": [
    "f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "# data = f.read()\n",
    "data = jams.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gOys91nXrHn",
    "outputId": "bcb333e8-0b4d-4e9a-cfab-4b690efa9a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttime\tduration\tnotes\n",
      "[[1.0279111111111092, 0.13351473922902812, 49.193803230707154],\n",
      " [1.304237641723354, 0.08707482993197146, 52.114584297971554],\n",
      " [1.3941242630385489, 0.23800453514738962, 53.06152785960328],\n",
      " [1.679385034013606, 0.13931972789115576, 56.14443073972567],\n",
      " [1.9566866213151926, 0.2902494331065739, 56.17702536590502],\n",
      " [2.3031265306122393, 0.09287981859410621, 53.08339188734166],\n",
      " [2.6073442176870714, 0.12190476190475863, 57.14782805032149],\n",
      " [2.9405641723355984, 0.12190476190475863, 60.91999064053075],\n",
      " [3.2740108843537357, 0.09868480725623385, 60.33037973363317],\n",
      " [3.5828317460317436, 0.5050340136054388, 61.522481510672925],\n",
      " [4.3526956916099735, 0.11029478458049624, 57.98474034208964],\n",
      " [4.642673015873008, 0.09287981859410621, 59.10588569730126],\n",
      " [4.9913351473922845, 0.7372335600907007, 61.11095551176679],\n",
      " [7.287298866213149, 0.2844444444444463, 63.46856030989381],\n",
      " [7.575303401360543, 0.7488435374149631, 61.16104776571266],\n",
      " [8.350292063492056, 0.4063492063492049, 61.07104616813202],\n",
      " [9.191947392290245, 0.34829931972789296, 58.130468792076336],\n",
      " [9.60516734693877, 0.19156462585034006, 61.04760266748758],\n",
      " [9.931629931972786, 0.12190476190475863, 60.96265834049261],\n",
      " [10.227457596371877, 0.09868480725623385, 61.10339381865027],\n",
      " [10.243285260770975, 0.17414965986394293, 66.07918933940174],\n",
      " [10.330405442176868, 0.19156462585034006, 63.071217373455866],\n",
      " [10.580178684807251, 1.7414965986394577, 61.029490998705384],\n",
      " [12.344010884353736, 0.2902494331065739, 63.02975379425347],\n",
      " [12.963375963718825, 0.18575963718820532, 60.04424018968106],\n",
      " [14.646709297052155, 0.3424943310657582, 61.19650871610332],\n",
      " [15.038750113378683, 0.13351473922902812, 59.19028862302168],\n",
      " [15.313580045351472, 0.30766439909297105, 56.15785998263231],\n",
      " [15.66337596371882, 0.2205895691609996, 54.13586668937021],\n",
      " [16.014963265306122, 0.1683446712018153, 52.15127906965688],\n",
      " [16.18541678004535, 0.29605442176870866, 53.074780089508636],\n",
      " [16.629521088435368, 0.3250793650793682, 56.19055404450025],\n",
      " [16.99135782312925, 0.12770975056689338, 53.11079410590745],\n",
      " [17.28090430839002, 0.09868480725623385, 57.17666297325452],\n",
      " [17.382423582766435, 0.2205895691609996, 58.16911443192291],\n",
      " [17.651017687074827, 0.1451247165532905, 61.14039932138798],\n",
      " [17.981561904761904, 0.2728344671201839, 61.188743639547795],\n",
      " [18.35450975056689, 0.12770975056689338, 58.15561157387588],\n",
      " [18.69546213151927, 0.2612244897959215, 63.997777531730954],\n",
      " [18.99822857142857, 0.22639455782312723, 64.96759007574646],\n",
      " [19.319611791383224, 0.25541950113378675, 66.01238105686467],\n",
      " [19.62607437641723, 0.1567346938775529, 66.9166629345382],\n",
      " [19.97033741496599, 0.1567346938775529, 68.01431148580971],\n",
      " [20.27534875283446, 0.1044897959183686, 64.0575556193237],\n",
      " [20.380473469387752, 0.2089795918367372, 64.9991923011718],\n",
      " [20.62541678004535, 0.35990929705215535, 64.00033837455311],\n",
      " [20.9475029478458, 1.851791383219954, 61.26363548055802],\n",
      " [22.99539410430838, 0.17414965986394293, 59.12818174753737],\n",
      " [23.340632199546484, 0.1683446712018153, 61.1600820812153],\n",
      " [23.61423764172335, 0.789478458049885, 64.06396923421042],\n",
      " [24.641357823129248, 0.1044897959183686, 66.00861073591436],\n",
      " [24.74723083900227, 0.17414965986394293, 64.11276359640748],\n",
      " [24.94453242630385, 0.18575963718820532, 66.032783635642],\n",
      " [25.15875011337868, 0.09287981859410621, 67.19803729257208],\n",
      " [25.253716099773236, 0.20317460317460245, 66.0198752191348],\n",
      " [25.27201541950113, 0.15092970521541815, 71.04217727643287],\n",
      " [25.46042811791383, 0.26702947845805625, 63.99238383352031],\n",
      " [25.492378231292513, 0.18575963718821242, 69.07219698109468],\n",
      " [25.622582312925168, 0.2844444444444463, 61.20000985682169],\n",
      " [25.961335147392283, 0.3250793650793611, 64.11762169173578],\n",
      " [26.308750113378686, 0.19156462585034717, 61.13975020157838],\n",
      " [26.61899954648525, 0.2844444444444463, 64.02247753801463],\n",
      " [26.76634648526076, 0.4179591836734744, 61.24985241703892],\n",
      " [27.668523356009068, 0.18575963718821242, 59.14715525330357],\n",
      " [27.98990657596371, 0.12190476190475863, 57.175316301112694],\n",
      " [28.12478185941044, 0.17414965986394293, 58.141876204530355],\n",
      " [28.341902040816315, 0.16253968253968765, 61.17543650693899],\n",
      " [28.65940770975056, 0.26702947845805625, 56.198766081636904],\n",
      " [28.977888435374147, 0.17995464852607768, 54.123299442837535],\n",
      " [29.307230839002266, 0.13351473922902812, 52.18108902213385],\n",
      " [29.441403174603174, 0.15092970521541815, 53.04476962482797],\n",
      " [29.641607256235822, 0.12770975056689338, 56.18843032645662],\n",
      " [29.949090249433105, 0.08707482993197857, 57.17358641767831],\n",
      " [30.291902040816318, 0.8243083900226793, 61.40869026182239]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ttime\\tduration\\tnotes\")\n",
    "pprint.pprint(loadNoteData(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "pFxIOfooXu4X"
   },
   "outputs": [],
   "source": [
    "#File loading Test\n",
    "for song,jam in inputFiles:\n",
    "  if song[:-13] != jam[:-10]:\n",
    "    print(\"error with:\",song,jam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test XData padding\n",
    "for x in XData:\n",
    "  if len(x) < 4096:\n",
    "    print(\"Error with Xdata padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check to see if XData and YData arrays are being appended properly\n",
    "if notecounter != len(XData):\n",
    "  print(\"Error: XData and YData arrays are not being apppended properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI \tNote  \tFreq \t\t\tTime\n",
      "50.0 \t D3 \t 146.8323839587038 \t 1.8575963718820863\n",
      "60.0 \t C4 \t 261.6255653005986 \t 1.9504761904761905\n",
      "60.0 \t C4 \t 261.6255653005986 \t 3.9706122448979593\n",
      "50.0 \t D3 \t 146.8323839587038 \t 5.828208616780046\n",
      "60.0 \t C4 \t 261.6255653005986 \t 7.894784580498866\n",
      "60.0 \t C4 \t 261.6255653005986 \t 20.456780045351476\n",
      "60.0 \t C4 \t 261.6255653005986 \t 21.91963718820862\n",
      "69.0 \t A4 \t 440.0 \t 22.709115646258503\n"
     ]
    }
   ],
   "source": [
    "# From the predict() function above to get the note and time info we can see what note and freq it represents\n",
    "\n",
    "# Reference: https://pythonhosted.org/audiolazy/lazy_midi.html\n",
    "\n",
    "print('MIDI \\tNote  \\tFreq \\t\\t\\tTime')\n",
    "for note, time in midi_info:\n",
    "    if note != 0.0:\n",
    "        print(note,'\\t',al.midi2str(note),'\\t',al.midi2freq(note),'\\t',time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seng474Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
