{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Xd1XGIwwB7Lg"
   },
   "outputs": [],
   "source": [
    "# convert to a '.py' file\n",
    "#!jupyter nbconvert --to script *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jams in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (0.3.4)\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (4.4.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (2.4.0)\n",
      "Requirement already satisfied: pandas in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (1.1.3)\n",
      "Requirement already satisfied: six in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (1.21.5)\n",
      "Requirement already satisfied: mir-eval>=0.5 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (0.7)\n",
      "Requirement already satisfied: decorator in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jams) (5.1.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jsonschema>=3.0.0->jams) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jsonschema>=3.0.0->jams) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from jsonschema>=3.0.0->jams) (21.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.0->jams) (3.7.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from mir-eval>=0.5->jams) (1.7.3)\n",
      "Requirement already satisfied: future in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from mir-eval>=0.5->jams) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from pandas->jams) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from pandas->jams) (2020.1)\n",
      "Requirement already satisfied: matplotlib in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: audiolazy in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (0.6)\n",
      "Requirement already satisfied: librosa in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: numba>=0.45.1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (58.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from packaging>=20.0->librosa) (3.0.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.8)\n",
      "Requirement already satisfied: six>=1.3 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from scikit-learn>=0.19.1->librosa) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "pwshn6LfKd5X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQE8nV4nh1f2"
   },
   "source": [
    "## Process input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "Zn8-Wa-XEcV9"
   },
   "outputs": [],
   "source": [
    "def timeKey(t):\n",
    "    return t[0]\n",
    "\n",
    "def loadNoteData(f):\n",
    "    #f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "   # data = f.read()\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    #pprint.pprint(notes)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "        source_audio = audio.astype(np.float32) / max(max(audio),abs(min(audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function to process the raw audio data.\n",
    "def x_data_process(raw_data):\n",
    "    scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "    scaled = scaler.fit_transform(raw_data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change this so it pads to match the shape of frame. not just the length\n",
    "def pad(proper_size, frame):\n",
    "    padsize = winSize-len(frame)\n",
    "    temp = None\n",
    "    if len(frame.shape) > 1:\n",
    "        temp = np.zeros((frame.shape[0],padsize))\n",
    "    else:\n",
    "        temp = np.zeros(padsize)\n",
    "\n",
    "    return np.concatenate((frame,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "iBBc63iIocsB"
   },
   "outputs": [],
   "source": [
    "# iterate through each song, one frame at a time based off hop and window size\n",
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  testCount = 0\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    testCount += 1\n",
    "\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = audio[o:o+winSize]\n",
    "\n",
    "    if original_frame_size == 0:\n",
    "      original_frame_size = frame.shape\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels,testCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Taking the song path, trained model, and same hopSize and winSize as used in training,\n",
    "Converts song into predicted midi information\"\"\"\n",
    "def predict(song_path, model, hopSize, winSize):\n",
    "    \n",
    "    audio,sr = load_audio_file(song_path, scale=False)\n",
    "    offsets = np.arange(0,len(audio),hopSize)\n",
    "    x_data = []\n",
    "    for (i,o) in enumerate(offsets):\n",
    "        frame = audio[o:o+winSize]\n",
    "        #pad\n",
    "        if len(frame) < winSize:\n",
    "            frame = pad(winSize, frame)\n",
    "\n",
    "        #append to features\n",
    "        x_data.append(frame)\n",
    "\n",
    "    #preprocess data\n",
    "    x_data = x_data_process(x_data)\n",
    "\n",
    "    #column 0 is note, column 1 is time\n",
    "    midi_info = np.zeros((len(offsets),2))\n",
    "    raw_results = model.predict(x_data)\n",
    "\n",
    "    for i,frame_note in enumerate(raw_results):\n",
    "        midi_info[i][0] = frame_note\n",
    "        midi_info[i][1] = hopSize*i/sr\n",
    "\n",
    "        #TODO: create proper midi file from this note / time information\n",
    "          #Also determine method to covert midi into sheet music\n",
    "\n",
    "    return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IULUskjWZhR"
   },
   "source": [
    "## Data classification using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "zQ3YbkqhXLv9"
   },
   "outputs": [],
   "source": [
    "def neuralNetwork(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=(71, 21), max_iter=10000, alpha=0.0001, learning_rate_init=0.001, solver='adam')\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shawn_nn(XTrain, XTest, YTrain, YTest, hidden_size, max_iter, solver, activation):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=hidden_size, max_iter=max_iter, alpha=0.0001, \n",
    "                         learning_rate_init=0.001, solver=solver, activation=activation)\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ba6L3QgXODZ"
   },
   "source": [
    "## Data classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "A1pTsklKXPcL"
   },
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    svc = SVC(kernel = 'rbf', gamma = 0.1, C = 10)\n",
    "    svc.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, svc.predict(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "BmNXFTYPgFBL"
   },
   "outputs": [],
   "source": [
    "def linearSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    svc = LinearSVC(C = 0.0225)\n",
    "\n",
    "    svc.fit(XTrain, YTrain)\n",
    "    accuracy_score(YTest, svc.predict(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8DfjYyNg0NZ"
   },
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "CkZh6bSmKhw3"
   },
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 5\n",
    "counter = numSongs\n",
    "\n",
    "notecounter = 0\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "    song = os.path.join(song_path,song_file)\n",
    "    jam = os.path.join(jam_path,jam_file)\n",
    "    \n",
    "    audio_prescaled,sr = load_audio_file(song,scale=True)\n",
    "    audio,sr = load_audio_file(song, scale=False)\n",
    "    note_info = loadNoteData(jam)\n",
    "\n",
    "    #NOTE: window size used in previous works with dataset where 0.2s\n",
    "    XData_prescaled,YData,notecount = songProcess(audio_prescaled,note_info,sr, hopSize=hopSize, winSize = winSize) # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "\n",
    "\n",
    "    XData,YData,notecount = songProcess(audio,note_info,sr, hopSize=hopSize, winSize = winSize) # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "\n",
    "\n",
    "    notecounter += notecount\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XData_prescaled = np.array(XData_prescaled)\n",
    "# XData_prescaled = XData_prescaled / max(XData_prescaled.max(), abs(XData_prescaled.min()))\n",
    "# print(X1.min(axis=0))\n",
    "# print(X1.max(axis=0))\n",
    "\n",
    "# XData_post = np.array(x_data_process(XData))\n",
    "# print(X2.min(axis=0))\n",
    "# print(X2.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 accuracy: 0.5180363439110388\n",
      "Method 2 accuracy: 0.47206400867914294\n",
      "Control. No scaling accuracy: 0.279224301600217\n"
     ]
    }
   ],
   "source": [
    "### XDATA SCALING EXPERIMENT\n",
    "#Method 1: perform a -1,1 scale on the audio file at initial loading. This scales audio files individually, not recognizing the values of other files\n",
    "#Method 2: perform a -1,1 scale at train test split via sklearn. This scaled audio files together, after they are loaded and concatenated.\n",
    "#Method 3: control. No scaling\n",
    "XData_prescaled = np.array(XData_prescaled)\n",
    "XData_prescaled = XData_prescaled / max(XData_prescaled.max(), abs(XData_prescaled.min()))\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "N_avg = 3\n",
    "results = {}\n",
    "for j,xdata in enumerate((XData_prescaled,XData_postscaled,XData)):\n",
    "    results[j] = 0\n",
    "    XTrain,XTest,YTrain,YTest = train_test_split(xdata,YData,test_size=0.2)\n",
    "    for i in range(N_avg):\n",
    "        results[j] += neuralNetwork(XTrain,XTest,YTrain,YTest)[0]\n",
    "    results[j] /= N_avg\n",
    "\n",
    "print(\"Method 1 accuracy:\",results[0])\n",
    "print(\"Method 2 accuracy:\",results[1])\n",
    "print(\"Control. No scaling accuracy:\",results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/shawnnettleton/opt/miniconda3/envs/apress/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# using shawns models to compare method accuracies \n",
    "XData_prescaled = np.array(XData_prescaled)\n",
    "XData_prescaled = XData_prescaled / max(XData_prescaled.max(), abs(XData_prescaled.min()))\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "hidden_size=(60,60)\n",
    "max_iter=100000\n",
    "solver='lbfgs'\n",
    "activation='relu'\n",
    "\n",
    "N_avg = 3\n",
    "results = {}\n",
    "for j,xdata in enumerate((XData_prescaled,XData_postscaled,XData)):\n",
    "    results[j] = 0\n",
    "    XTrain,XTest,YTrain,YTest = train_test_split(xdata,YData,test_size=0.2)\n",
    "    for i in range(N_avg):\n",
    "        results[j] = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)[0]\n",
    "    results[j] /= N_avg\n",
    "\n",
    "print(\"Method 1 accuracy:\",results[0])\n",
    "print(\"Method 2 accuracy:\",results[1])\n",
    "print(\"Control. No scaling accuracy:\",results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training - Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.45402766476810413\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = neuralNetwork(XTrain,XTest,YTrain,YTest)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.6265256305939788\n"
     ]
    }
   ],
   "source": [
    "# Shawn's Testing - best model so far\n",
    "XData_postscaled = x_data_process(XData)\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "hidden_size=(60,60)\n",
    "max_iter=100000\n",
    "solver='lbfgs'\n",
    "activation='relu'\n",
    "accuracy, trained_model = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.7046379170056957\n"
     ]
    }
   ],
   "source": [
    "# Shawn's Testing - best model so far\n",
    "XData_postscaled = x_data_process(XData)\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_prescaled,YData,test_size=0.2)\n",
    "hidden_size=(60,60)\n",
    "max_iter=100000\n",
    "solver='lbfgs'\n",
    "activation='relu'\n",
    "accuracy, trained_model = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [0.         0.02321995]\n",
      " [0.         0.04643991]\n",
      " [0.         0.06965986]\n",
      " [0.         0.09287982]\n",
      " [0.         0.11609977]\n",
      " [0.         0.13931973]\n",
      " [0.         0.16253968]\n",
      " [0.         0.18575964]\n",
      " [0.         0.20897959]]\n"
     ]
    }
   ],
   "source": [
    "## Call predict function\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "midi_info = predict(song, trained_model, hopSize, winSize)\n",
    "\n",
    "# print(midi_info[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNV465-nwiWH"
   },
   "source": [
    "## Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YZJnOBjgghz7"
   },
   "outputs": [],
   "source": [
    "f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "# data = f.read()\n",
    "data = jams.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gOys91nXrHn",
    "outputId": "bcb333e8-0b4d-4e9a-cfab-4b690efa9a2b"
   },
   "outputs": [],
   "source": [
    "print(\"\\ttime\\tduration\\tnotes\")\n",
    "pprint.pprint(loadNoteData(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "pFxIOfooXu4X"
   },
   "outputs": [],
   "source": [
    "#File loading Test\n",
    "for song,jam in inputFiles:\n",
    "    if song[:-13] != jam[:-10]:\n",
    "        print(\"error with:\",song,jam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test XData padding\n",
    "for x in XData:\n",
    "    if len(x) < 4096:\n",
    "        print(\"Error with Xdata padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check to see if XData and YData arrays are being appended properly\n",
    "if notecounter != len(XData):\n",
    "    print(\"Error: XData and YData arrays are not being apppended properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI \tNote  \tFreq \t\t\tTime\n",
      "50.0 \t D3 \t 146.8323839587038 \t 1.8575963718820863\n",
      "60.0 \t C4 \t 261.6255653005986 \t 1.9504761904761905\n",
      "60.0 \t C4 \t 261.6255653005986 \t 3.9706122448979593\n",
      "50.0 \t D3 \t 146.8323839587038 \t 5.828208616780046\n",
      "60.0 \t C4 \t 261.6255653005986 \t 7.894784580498866\n",
      "60.0 \t C4 \t 261.6255653005986 \t 20.456780045351476\n",
      "60.0 \t C4 \t 261.6255653005986 \t 21.91963718820862\n",
      "69.0 \t A4 \t 440.0 \t 22.709115646258503\n"
     ]
    }
   ],
   "source": [
    "# From the predict() function above to get the note and time info we can see what note and freq it represents\n",
    "\n",
    "# Reference: https://pythonhosted.org/audiolazy/lazy_midi.html\n",
    "\n",
    "print('MIDI \\tNote  \\tFreq \\t\\t\\tTime')\n",
    "for note, time in midi_info:\n",
    "    if note != 0.0:\n",
    "        print(note,'\\t',al.midi2str(note),'\\t',al.midi2freq(note),'\\t',time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seng474Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
