{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jams in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (4.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.15.0)\n",
      "Requirement already satisfied: mir-eval>=0.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (0.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.4.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (2.4.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.19.5)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0.0->jams) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0.0->jams) (21.4.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mir-eval>=0.5->jams) (1.8.0)\n",
      "Requirement already satisfied: future in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mir-eval>=0.5->jams) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->jams) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->jams) (2.8.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Collecting audiolazy\n",
      "  Using cached audiolazy-0.6-py2.py3-none-any.whl (121 kB)\n",
      "Installing collected packages: audiolazy\n",
      "Successfully installed audiolazy-0.6\n",
      "Requirement already satisfied: librosa in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (49.2.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: music21 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.1.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.1.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.11.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (3.5.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (8.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.19.5)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (2.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.15.0)\n",
      "Requirement already satisfied: MIDIUtil in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy\n",
    "!pip install librosa\n",
    "!pip3 install music21\n",
    "!pip3 install MIDIUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al\n",
    "\n",
    "import music21\n",
    "from midiutil import MIDIFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data Input (Guitar Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract note/time information from JAM file\n",
    "def loadNoteData(f):\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    return notes\n",
    "\n",
    "# Helper function for JAM file processing\n",
    "def timeKey(t):\n",
    "    return t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle loading audio files\n",
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "        source_audio = source_audio.astype(np.float32) / max(max(source_audio),abs(min(source_audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the raw audio data (x data)\n",
    "# local - uses sklearn MinMaxScaler. each \"frame\" has local -1,1 scaling\n",
    "# global - entire x dataset scaled by largest absolute value to -1,1\n",
    "def x_data_process(raw_data, scale = 'local'):\n",
    "    if scale == 'local':\n",
    "        scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "        scaled = scaler.fit_transform(raw_data)\n",
    "    elif scale == 'global':\n",
    "        scaled = raw_data.copy() / max(np.absolute(np.array(raw_data).flatten()))\n",
    "    else:\n",
    "        scaled = raw_data\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad x data so all frames are same length\n",
    "def pad(proper_size, frame):\n",
    "    padsize = winSize-len(frame)\n",
    "    temp = None\n",
    "    if len(frame.shape) > 1:\n",
    "        temp = np.zeros((frame.shape[0],padsize))\n",
    "    else:\n",
    "        temp = np.zeros(padsize)\n",
    "\n",
    "    return np.concatenate((frame,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create x data and y data lists from audio files and jam files\n",
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = audio[o:o+winSize]\n",
    "\n",
    "    if original_frame_size == 0:\n",
    "      original_frame_size = frame.shape\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform T-SNE dimension reduction\n",
    "def tsneFit(X, comps):\n",
    "    tsne = TSNE(comps, learning_rate='auto', init='pca')\n",
    "    result = tsne.fit_transform(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use input song and a trained model, to predict song's note/time information in MIDI\n",
    "def predict(song_audio, sr, model, hopSize, winSize):\n",
    "    \n",
    "    offsets = np.arange(0,len(song_audio),hopSize)\n",
    "    x_data = []\n",
    "\n",
    "    for (i,o) in enumerate(offsets):\n",
    "        frame = song_audio[o:o+winSize]\n",
    "        #pad\n",
    "        if len(frame) < winSize:\n",
    "            frame = pad(winSize, frame)\n",
    "        #append to features\n",
    "        x_data.append(frame)\n",
    "\n",
    "    #preprocess data\n",
    "    x_data = x_data_process(x_data,scale='global')\n",
    "\n",
    "    #predict. column 0 is note, column 1 is time\n",
    "    raw_results = model.predict(x_data)\n",
    "    midi_info = np.zeros((len(offsets),3))\n",
    "\n",
    "    for i,frame_note in enumerate(raw_results):\n",
    "        midi_info[i][0] = frame_note\n",
    "        midi_info[i][1] = hopSize*i/sr\n",
    "    midi_info[:,2] = np.absolute(np.array(x_data)).mean(axis=1) #amplitude of each frame\n",
    "\n",
    "    return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheet Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sheet music from the note/time information output from predict()\n",
    "# TODO: Condense note/time input into min 8th notes\n",
    "#          Save stream to midi file\n",
    "def to_midi_sheet(midi_info,outfile,bpm=120):\n",
    "    degrees = []\n",
    "    error = 0.2\n",
    "    q_length = 60/bpm #length of quarter note in seconds\n",
    "    min_note = q_length/2/2/2 # length of 32nd note\n",
    "    curr_note_dur = 0\n",
    "\n",
    "    s = music21.stream.Stream([music21.clef.TrebleClef()])\n",
    "\n",
    "    for i in range(1,len(midi_info)):\n",
    "        # curr_note = int(midi_info[i][0])\n",
    "        # prev_note = int(midi_info[i-1][0])\n",
    "        # \n",
    "        # if curr_note != prev_note:\n",
    "        #     curr_note_start = midi_info[i][1] \n",
    "        # \n",
    "        # \n",
    "        # \n",
    "        # if midi_info[i][0] == midi_info[i-1][0] and midi_info[i][2] > (1+error)* midi_info[i-1][2]:\n",
    "\n",
    "\n",
    "        if pitch == 0:\n",
    "            s.append(music21.note.Rest(quarterLength=1))\n",
    "        else:\n",
    "            s.append(music21.note.Note(pitch,quarterLength=1))\n",
    "\n",
    "    s.show('musicxml.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "s = music21.stream.Stream()\n",
    "s.append(music21.note.Note(70,quarterLength = 1))\n",
    "s.append(music21.note.Rest(quarterLength = 1))\n",
    "s.append(music21.note.Rest(quarterLength = 1))\n",
    "s.append(music21.note.Note(72,quarterLength = 1))\n",
    "s.show('musicxml.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Driver to load data and # of songs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 5\n",
    "counter = numSongs\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "    song = os.path.join(song_path,song_file)\n",
    "    jam = os.path.join(jam_path,jam_file)\n",
    "\n",
    "    audio,sr = load_audio_file(song)\n",
    "    note_info = loadNoteData(jam)\n",
    "\n",
    "    # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "    XData,YData = songProcess(audio,note_info,sr, hopSize, winSize)\n",
    "\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network Model Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def neural_network(XTrain, XTest, YTrain, YTest, hidden_size, max_iter, solver, activation):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=hidden_size, max_iter=max_iter, alpha=0.0001,\n",
    "                         learning_rate_init=0.001, solver=solver, activation=activation)\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.5311355311355311\n"
     ]
    }
   ],
   "source": [
    "# NN Using No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.01389017516934801 0.017814734977924275\n",
      "0.0 0.010834799693056731 0.0242384064654651\n",
      "0.0 0.020743831838937944 0.03468657387806943\n",
      "0.0 0.016221190992802708 0.03017326512791823\n",
      "54.0 0.1287523294801621 0.2149207693238176\n",
      "62.0 0.030298126209628642 0.039167397483972424\n",
      "66.0 0.09823176862828112 0.12572967540371355\n",
      "54.0 0.11123385901778153 0.23328113659731464\n",
      "62.0 0.030673772604935284 0.03891590340359259\n",
      "62.0 0.05491135217581952 0.07475398704941333\n",
      "0.0 0.03706389579805249 0.06261210327960566\n",
      "54.0 0.15372950718973027 0.21352000990383452\n",
      "0.0 0.013277564412725292 0.024828809196201763\n",
      "54.0 0.24957119609592354 0.3350823728755897\n",
      "59.0 0.04642138925849764 0.059240263434438126\n",
      "67.0 0.06211596653108746 0.07812370059423007\n",
      "0.0 0.039511385629611706 0.10927801707844442\n",
      "0.0 0.0071130653123865975 0.018916276687431958\n",
      "0.0 0.009802244617152536 0.020144215140014514\n",
      "0.0 0.004697588113886536 0.006246597919438731\n",
      "0.0 0.006047552581045119 0.008880020903895005\n",
      "0.0 0.006371104617757349 0.010532156276460626\n",
      "0.0 0.0060866528819402445 0.009684471203278092\n",
      "66.0 0.03218864347707753 0.09671689775613887\n",
      "0.0 0.012922354126345712 0.017507484577234788\n",
      "0.0 0.017507484577234788 0.024668037264122415\n",
      "0.0 0.014726283718398452 0.03242820664993347\n",
      "0.0 0.017714680733639774 0.047287266012459174\n",
      "0.0 0.010669538904681263 0.013562134276339663\n",
      "0.0 0.013562134276339663 0.021548754649510102\n",
      "62.0 0.03694222416686827 0.07721647911122537\n",
      "62.0 0.07721647911122537 0.09899676424337728\n",
      "0.0 0.02259229561056006 0.0332223798309544\n",
      "0.0 0.010543496544998185 0.022124037022196688\n",
      "0.0 0.00937674829139954 0.02196976211896698\n",
      "0.0 0.02196976211896698 0.029799272521773317\n",
      "0.0 0.007718470273376073 0.013021817731643884\n",
      "0.0 0.010665758815168742 0.017161842642433773\n",
      "66.0 0.14171224824603845 0.22839796971392284\n",
      "0.0 0.011549000355328413 0.01980235329472602\n",
      "0.0 0.005717503515483247 0.017650182956332406\n",
      "0.0 0.012129362223297448 0.018215896977440426\n",
      "0.0 0.018215896977440426 0.025039903569916536\n",
      "0.0 0.006838181928148059 0.010780460906314262\n",
      "0.0 0.00696316113765574 0.009613240141526551\n",
      "0.0 0.003493865859743559 0.004470546487540825\n",
      "0.0 0.004470546487540825 0.01145237181716463\n",
      "0.0 0.01145237181716463 0.015893976994375225\n",
      "64.0 0.07419725074089754 0.10249488270382243\n",
      "0.0 0.028723482672069676 0.049657618392403534\n",
      "0.0 0.02793096328021048 0.08985024702884964\n",
      "55.0 0.16058824335460264 0.267137980827386\n",
      "57.0 0.04626309801016089 0.05973332886022741\n",
      "54.0 0.11717793164842144 0.16448409810844322\n",
      "0.0 0.026954282652413206 0.03849276963378492\n",
      "55.0 0.3204863841175759 0.42652663640074995\n",
      "0.0 0.026629667465525583 0.08209811033325268\n",
      "54.0 0.2389152418879279 0.35829861951131003\n",
      "54.0 0.0717540135100399 0.09300390483246643\n",
      "52.0 0.046810738478287164 0.06137754967037619\n",
      "0.0 0.022354149971271317 0.028980174375529216\n",
      "0.0 0.03947878235756623 0.04962785018749244\n",
      "43.0 0.23481018280512883 0.41938569292820854\n",
      "54.0 0.14669062613402684 0.22914276547568646\n",
      "45.0 0.08212787853816378 0.26045549133603485\n",
      "0.0 0.006790458298052497 0.014262632114128461\n",
      "0.0 0.012016077665719124 0.02045477311902746\n",
      "0.0 0.02045477311902746 0.04686460475384057\n",
      "0.0 0.04686460475384057 0.06787635043697834\n",
      "45.0 0.07073823258134752 0.09453460482944237\n"
     ]
    }
   ],
   "source": [
    "error = 0.15\n",
    "\n",
    "for i in range(1,len(midi_info)):\n",
    "    if midi_info[i][0] == midi_info[i-1][0] and midi_info[i][2] > (1+0.25)* midi_info[i-1][2]:\n",
    "        print(midi_info[i][0],\n",
    "              midi_info[i-1][2],\n",
    "              midi_info[i][2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_nn_sheet_music\",bpm=round(bpm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NN Using local Scaling\n",
    "\n",
    "XData_local = x_data_process(XData, scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"local_nn_sheet_music\",bpm=round(bpm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Using global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"global_nn_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Using TSNE Reduction with local scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_nn_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'rbf', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polySVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'poly', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'sigmoid', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'precomputed', C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel - Gaussian SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - Local Scaling\n",
    "XDATA_local = x_data_process(XData,scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"local_rbf_sheet_music\", bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - Global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "#song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"global_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - TSNE Scaling with local scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = librosa.load(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly Kernel - Polynomial SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "PSVM_1_accuracy, PSVM_1 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_1_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - Local Scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "PSVM_2_accuracy, PSVM_2 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_2_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"local_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - Global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "PSVM_3_accuracy, PSVM_3 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_3_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"global_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - TSNE Scaling with local scaling\n",
    "XData_local = x_data_process(XData, scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "PSVM_4_accuracy, PSVM_4 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_4_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel - Sigmoid SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seng474Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}