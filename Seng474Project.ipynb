{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xd1XGIwwB7Lg"
   },
   "outputs": [],
   "source": [
    "# convert to a '.py' file\n",
    "#!jupyter nbconvert --to script *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pwshn6LfKd5X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQE8nV4nh1f2"
   },
   "source": [
    "## Process input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Zn8-Wa-XEcV9"
   },
   "outputs": [],
   "source": [
    "def timeKey(t):\n",
    "    return t[0]\n",
    "\n",
    "def loadNoteData(f):\n",
    "    #f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "   # data = f.read()\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    #pprint.pprint(notes)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "        source_audio = source_audio.astype(np.float32) / max(max(source_audio),abs(min(source_audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function to process the raw audio data.\n",
    "def x_data_process(raw_data):\n",
    "    scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "    scaled = scaler.fit_transform(raw_data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change this so it pads to match the shape of frame. not just the length\n",
    "def pad(proper_size, frame):\n",
    "    padsize = winSize-len(frame)\n",
    "    temp = None\n",
    "    if len(frame.shape) > 1:\n",
    "        temp = np.zeros((frame.shape[0],padsize))\n",
    "    else:\n",
    "        temp = np.zeros(padsize)\n",
    "\n",
    "    return np.concatenate((frame,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iBBc63iIocsB"
   },
   "outputs": [],
   "source": [
    "# iterate through each song, one frame at a time based off hop and window size\n",
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  testCount = 0\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    testCount += 1\n",
    "\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = audio[o:o+winSize]\n",
    "\n",
    "    if original_frame_size == 0:\n",
    "      original_frame_size = frame.shape\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels,testCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsneFit(X, comps):\n",
    "    tsne = TSNE(comps, learning_rate='auto', init='pca')\n",
    "    result = tsne.fit_transform(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Taking the song path, trained model, and same hopSize and winSize as used in training,\n",
    "Converts song into predicted midi information\"\"\"\n",
    "def predict(song_path, model, hopSize, winSize):\n",
    "    \n",
    "    audio,sr = load_audio_file(song_path, scale=False)\n",
    "    offsets = np.arange(0,len(audio),hopSize)\n",
    "    x_data = []\n",
    "    for (i,o) in enumerate(offsets):\n",
    "        frame = audio[o:o+winSize]\n",
    "        #pad\n",
    "        if len(frame) < winSize:\n",
    "            frame = pad(winSize, frame)\n",
    "\n",
    "        #append to features\n",
    "        x_data.append(frame)\n",
    "\n",
    "    #preprocess data\n",
    "    x_data = x_data_process(x_data)\n",
    "\n",
    "    #column 0 is note, column 1 is time\n",
    "    midi_info = np.zeros((len(offsets),2))\n",
    "    raw_results = model.predict(x_data)\n",
    "\n",
    "    for i,frame_note in enumerate(raw_results):\n",
    "        midi_info[i][0] = frame_note\n",
    "        midi_info[i][1] = hopSize*i/sr\n",
    "\n",
    "        #TODO: create proper midi file from this note / time information\n",
    "          #Also determine method to covert midi into sheet music\n",
    "\n",
    "    return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IULUskjWZhR"
   },
   "source": [
    "## Data classification using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zQ3YbkqhXLv9"
   },
   "outputs": [],
   "source": [
    "def neuralNetwork(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=(71, 21), max_iter=10000, alpha=0.0001, learning_rate_init=0.001, solver='adam')\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shawn_nn(XTrain, XTest, YTrain, YTest, hidden_size, max_iter, solver, activation):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=hidden_size, max_iter=max_iter, alpha=0.0001, \n",
    "                         learning_rate_init=0.001, solver=solver, activation=activation)\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ba6L3QgXODZ"
   },
   "source": [
    "## Data classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "A1pTsklKXPcL"
   },
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'rbf', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BmNXFTYPgFBL"
   },
   "outputs": [],
   "source": [
    "def linearSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    # svc = LinearSVC(C = 0.0225)\n",
    "    clf = LinearSVC(C = 1, max_iter=10000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "    \n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8DfjYyNg0NZ"
   },
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CkZh6bSmKhw3"
   },
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 15\n",
    "counter = numSongs\n",
    "\n",
    "notecounter = 0\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "    song = os.path.join(song_path,song_file)\n",
    "    jam = os.path.join(jam_path,jam_file)\n",
    "    \n",
    "    audio_prescaled,sr = load_audio_file(song,scale=True)\n",
    "    audio,sr = load_audio_file(song, scale=False)\n",
    "    note_info = loadNoteData(jam)\n",
    "\n",
    "    #NOTE: window size used in previous works with dataset where 0.2s\n",
    "    XData_prescaled,YData,notecount = songProcess(audio_prescaled,note_info,sr, hopSize=hopSize, winSize = winSize) # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "\n",
    "\n",
    "    XData,YData,notecount = songProcess(audio,note_info,sr, hopSize=hopSize, winSize = winSize) # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "\n",
    "\n",
    "    notecounter += notecount\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData_prescaled = np.array(XData_prescaled)\n",
    "XData_prescaled = XData_prescaled / max(XData_prescaled.max(), abs(XData_prescaled.min()))\n",
    "# print(X1.min(axis=0))\n",
    "# print(X1.max(axis=0))\n",
    "\n",
    "# XData_post = np.array(x_data_process(XData))\n",
    "# print(X2.min(axis=0))\n",
    "# print(X2.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XDATA SCALING EXPERIMENT\n",
    "#Method 1: perform a -1,1 scale on the audio file at initial loading. This scales audio files individually, not recognizing the values of other files\n",
    "#Method 2: perform a -1,1 scale at train test split via sklearn. This scaled audio files together, after they are loaded and concatenated.\n",
    "#Method 3: control. No scaling\n",
    "XData_prescaled = np.array(XData_prescaled)\n",
    "XData_prescaled = XData_prescaled / max(XData_prescaled.max(), abs(XData_prescaled.min()))\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "N_avg = 3\n",
    "results = {}\n",
    "for j,xdata in enumerate((XData_prescaled,XData_postscaled,XData)):\n",
    "    results[j] = 0\n",
    "    XTrain,XTest,YTrain,YTest = train_test_split(xdata,YData,test_size=0.2)\n",
    "    for i in range(N_avg):\n",
    "        results[j] += neuralNetwork(XTrain,XTest,YTrain,YTest)[0]\n",
    "    results[j] /= N_avg\n",
    "\n",
    "print(\"Method 1 accuracy:\",results[0])\n",
    "print(\"Method 2 accuracy:\",results[1])\n",
    "print(\"Control. No scaling accuracy:\",results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training - Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default Train model\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = neuralNetwork(XTrain,XTest,YTrain,YTest)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shawn's Testing - best model so far - takes about 20min to run however\n",
    "XData_postscaled = x_data_process(XData)\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_prescaled,YData,test_size=0.2)\n",
    "hidden_size=(80,120)\n",
    "max_iter=100000\n",
    "solver='lbfgs'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best of both - fast acting and good accuracy\n",
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_prescaled,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XDATA using TSNE\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = shawn_nn(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training - Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl of the linear models seems to suck. When C >= 1 it takes forever to run.\n",
    "\n",
    "# XDATA using TSNE\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "accuracy, trained_model = linearSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Linear SVM Model Test Accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_prescaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = linearSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Linear SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "accuracy, trained_model = linearSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Linear SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XDATA using TSNE\n",
    "XData_local = x_data_process(XData)\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_prescaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData_postscaled = x_data_process(XData)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_postscaled,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM Model Test Accuracy: 0.8623934137018524\n"
     ]
    }
   ],
   "source": [
    "# This will be the best model so far\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midi output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Call predict function\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "midi_info = predict(song, trained_model, hopSize, winSize)\n",
    "\n",
    "# print(midi_info[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNV465-nwiWH"
   },
   "source": [
    "## Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZJnOBjgghz7"
   },
   "outputs": [],
   "source": [
    "f = open('/content/JamsFiles/04_Rock1-90-C_solo.jams', 'r')\n",
    "\n",
    "# data = f.read()\n",
    "data = jams.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gOys91nXrHn",
    "outputId": "bcb333e8-0b4d-4e9a-cfab-4b690efa9a2b"
   },
   "outputs": [],
   "source": [
    "print(\"\\ttime\\tduration\\tnotes\")\n",
    "pprint.pprint(loadNoteData(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFxIOfooXu4X"
   },
   "outputs": [],
   "source": [
    "#File loading Test\n",
    "for song,jam in inputFiles:\n",
    "    if song[:-13] != jam[:-10]:\n",
    "        print(\"error with:\",song,jam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test XData padding\n",
    "for x in XData:\n",
    "    if len(x) < 4096:\n",
    "        print(\"Error with Xdata padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check to see if XData and YData arrays are being appended properly\n",
    "if notecounter != len(XData):\n",
    "    print(\"Error: XData and YData arrays are not being apppended properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the predict() function above to get the note and time info we can see what note and freq it represents\n",
    "\n",
    "# Reference: https://pythonhosted.org/audiolazy/lazy_midi.html\n",
    "\n",
    "print('MIDI \\tNote  \\tFreq \\t\\t\\tTime')\n",
    "for note, time in midi_info:\n",
    "    if note != 0.0:\n",
    "        print(note,'\\t',al.midi2str(note),'\\t',al.midi2freq(note),'\\t',time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seng474Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
